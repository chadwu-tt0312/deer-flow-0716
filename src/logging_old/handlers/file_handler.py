# Copyright (c) 2025 Bytedance Ltd. and/or its affiliates
# SPDX-License-Identifier: MIT

import logging
import os
import gzip
import shutil
from datetime import datetime, timedelta
from pathlib import Path
from ..config import LoggingConfig


class DeerFlowFileHandler(logging.Handler):
    """DeerFlow æª”æ¡ˆæ—¥èªŒè™•ç†å™¨"""

    def __init__(self, config: LoggingConfig = None):
        super().__init__()

        # å¦‚æœæ²’æœ‰å‚³å…¥ configï¼Œå˜—è©¦å¾ conf.yaml è®€å–
        if config is None:
            config = self._load_config_from_yaml()

        self.log_dir = Path(config.file_settings.get("log_dir", "logs"))
        self.max_days = config.file_settings.get("max_days", 10)
        self.compress_old_files = config.file_settings.get("compress_old_files", True)

        # ç¢ºä¿æ—¥èªŒç›®éŒ„å­˜åœ¨
        self.log_dir.mkdir(exist_ok=True)

        # æ¸…ç†èˆŠæª”æ¡ˆ
        self._cleanup_old_files()

    def _load_config_from_yaml(self) -> LoggingConfig:
        """å¾ conf.yaml è®€å–é…ç½®"""
        try:
            from ...config import load_yaml_config

            config = load_yaml_config("conf.yaml")
            logging_config = config.get("LOGGING", {})
            return LoggingConfig(logging_config)
        except Exception as e:
            print(f"âš ï¸ ç„¡æ³•å¾ conf.yaml è®€å–æ—¥èªŒé…ç½®: {e}")
            # è¿”å›é è¨­é…ç½®
            return LoggingConfig(
                {
                    "provider": "file",
                    "level": "INFO",
                    "file_settings": {
                        "log_dir": "logs",
                        "max_days": 10,
                        "compress_old_files": True,
                    },
                }
            )

    def emit(self, record):
        """ç™¼é€æ—¥èªŒè¨˜éŒ„åˆ°æª”æ¡ˆ"""
        try:
            # å–å¾—æª”æ¡ˆè·¯å¾‘
            # å„ªå…ˆä½¿ç”¨æ–°çš„ Thread-specific æ—¥èªŒç³»çµ±çš„ context
            thread_id = None

            # å˜—è©¦å¾ record çš„å±¬æ€§å–å¾— thread_id
            if hasattr(record, "thread_id"):
                thread_id = record.thread_id

            # å¦‚æœæ²’æœ‰ï¼Œå˜—è©¦å¾ extra å–å¾—
            if not thread_id and hasattr(record, "extra_data"):
                extra_data = getattr(record, "extra_data", {})
                if isinstance(extra_data, dict):
                    thread_id = extra_data.get("thread_id")

            # å¦‚æœé‚„æ˜¯æ²’æœ‰ï¼Œä½¿ç”¨é è¨­å€¼
            if not thread_id:
                thread_id = "default"

            file_path = self._get_log_file_path(thread_id)

            # å¯«å…¥æ—¥èªŒ
            with open(file_path, "a", encoding="utf-8") as f:
                f.write(self.format(record) + "\n")

        except Exception as e:
            # å¦‚æœæª”æ¡ˆå¯«å…¥å¤±æ•—ï¼Œè‡³å°‘è¼¸å‡ºåˆ° console
            print(f"File logging error: {e}")

    def _get_log_file_path(self, thread_id: str) -> Path:
        """å–å¾—æ—¥èªŒæª”æ¡ˆè·¯å¾‘"""
        date_str = datetime.now().strftime("%y%m%d")

        # è™•ç† thread_id ç‚º None æˆ– "default" çš„æƒ…æ³
        if thread_id and thread_id != "unknown" and thread_id != "default":
            # åªå–å‰8ç¢¼ä¾†ç¸®çŸ­æª”å
            short_thread_id = thread_id[:8]
            return self.log_dir / f"{date_str}-{short_thread_id}.log"
        else:
            # ä¸ä½¿ç”¨ "default" å¾Œç¶´ï¼Œç›´æ¥ä½¿ç”¨ä¸»æ—¥èªŒæª”æ¡ˆ
            return self.log_dir / f"{date_str}.log"

    def _cleanup_old_files(self):
        """æ¸…ç†èˆŠçš„æ—¥èªŒæª”æ¡ˆ"""
        cutoff_date = datetime.now() - timedelta(days=self.max_days)

        for log_file in self.log_dir.glob("*.log*"):
            try:
                # æª¢æŸ¥æª”æ¡ˆä¿®æ”¹æ™‚é–“
                file_mtime = datetime.fromtimestamp(log_file.stat().st_mtime)
                if file_mtime < cutoff_date:
                    # å¦‚æœå•Ÿç”¨å£“ç¸®ï¼Œå…ˆå£“ç¸®å†åˆªé™¤
                    if self.compress_old_files and log_file.suffix == ".log":
                        compressed_file = log_file.with_suffix(".log.gz")
                        with open(log_file, "rb") as f_in:
                            with gzip.open(compressed_file, "wb") as f_out:
                                shutil.copyfileobj(f_in, f_out)
                        log_file.unlink()  # åˆªé™¤åŸå§‹æª”æ¡ˆ
                        print(f"ğŸ“¦ å·²å£“ç¸®ä¸¦åˆªé™¤èˆŠæ—¥èªŒæª”æ¡ˆ: {log_file.name}")
                    else:
                        log_file.unlink()  # ç›´æ¥åˆªé™¤
                        print(f"ğŸ—‘ï¸ å·²åˆªé™¤èˆŠæ—¥èªŒæª”æ¡ˆ: {log_file.name}")
            except Exception as e:
                print(f"âš ï¸ æ¸…ç†æ—¥èªŒæª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    def close(self):
        """é—œé–‰è™•ç†å™¨"""
        super().close()
