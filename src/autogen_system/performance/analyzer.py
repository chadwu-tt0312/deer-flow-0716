# Copyright (c) 2025 Bytedance Ltd. and/or its affiliates
# SPDX-License-Identifier: MIT

"""
æ€§èƒ½åˆ†æå™¨

ç¶œåˆåˆ†æç³»çµ±æ€§èƒ½ä¸¦æä¾›æ·±åº¦æ´å¯Ÿã€‚
"""

import time
import statistics
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum

from src.logging import get_logger
from .metrics import PerformanceMetrics, MetricsCollector
from .profiler import ProfileResult

logger = get_logger(__name__)


class BottleneckType(Enum):
    """ç“¶é ¸é¡å‹"""

    CPU_BOUND = "cpu_bound"  # CPUå¯†é›†å‹ç“¶é ¸
    IO_BOUND = "io_bound"  # IOå¯†é›†å‹ç“¶é ¸
    MEMORY_BOUND = "memory_bound"  # å…§å­˜ç“¶é ¸
    NETWORK_BOUND = "network_bound"  # ç¶²çµ¡ç“¶é ¸
    LOCK_CONTENTION = "lock_contention"  # é–ç«¶çˆ­
    ALGORITHM = "algorithm"  # ç®—æ³•ç“¶é ¸


@dataclass
class Bottleneck:
    """ç“¶é ¸ä¿¡æ¯"""

    type: BottleneckType
    severity: float  # 0-1, 1æ˜¯æœ€åš´é‡
    description: str
    location: str  # ç“¶é ¸ä½ç½®
    impact: float  # å°æ•´é«”æ€§èƒ½çš„å½±éŸ¿ç™¾åˆ†æ¯”
    evidence: List[str] = field(default_factory=list)  # è­‰æ“š
    recommendations: List[str] = field(default_factory=list)  # å»ºè­°


@dataclass
class PerformanceTrend:
    """æ€§èƒ½è¶¨å‹¢"""

    metric_name: str
    trend_direction: str  # "improving", "degrading", "stable"
    change_rate: float  # è®ŠåŒ–ç‡ (%/æ™‚é–“å–®ä½)
    confidence: float  # ç½®ä¿¡åº¦ 0-1
    data_points: int  # æ•¸æ“šé»æ•¸é‡


@dataclass
class AnalysisResult:
    """åˆ†æçµæœ"""

    bottlenecks: List[Bottleneck] = field(default_factory=list)
    trends: List[PerformanceTrend] = field(default_factory=list)
    overall_score: float = 0.0  # ç¸½é«”æ€§èƒ½åˆ†æ•¸ 0-100
    insights: List[str] = field(default_factory=list)
    recommendations: List[str] = field(default_factory=list)
    analysis_timestamp: float = field(default_factory=time.time)


class PerformanceAnalyzer:
    """æ€§èƒ½åˆ†æå™¨"""

    def __init__(self):
        """åˆå§‹åŒ–æ€§èƒ½åˆ†æå™¨"""
        self.historical_data = []
        self.analysis_history = []

    def analyze_performance(
        self, metrics: PerformanceMetrics, profiler_result: ProfileResult = None
    ) -> AnalysisResult:
        """
        ç¶œåˆåˆ†ææ€§èƒ½

        Args:
            metrics: æ€§èƒ½æŒ‡æ¨™
            profiler_result: æ€§èƒ½åˆ†æçµæœ

        Returns:
            AnalysisResult: åˆ†æçµæœ
        """
        logger.info("é–‹å§‹ç¶œåˆæ€§èƒ½åˆ†æ")

        # è­˜åˆ¥ç“¶é ¸
        bottlenecks = self._identify_bottlenecks(metrics, profiler_result)

        # åˆ†æè¶¨å‹¢
        trends = self._analyze_trends(metrics)

        # è¨ˆç®—ç¸½é«”åˆ†æ•¸
        overall_score = self._calculate_overall_score(metrics, bottlenecks)

        # ç”Ÿæˆæ´å¯Ÿ
        insights = self._generate_insights(metrics, bottlenecks, trends)

        # ç”Ÿæˆå»ºè­°
        recommendations = self._generate_recommendations(bottlenecks, trends)

        result = AnalysisResult(
            bottlenecks=bottlenecks,
            trends=trends,
            overall_score=overall_score,
            insights=insights,
            recommendations=recommendations,
        )

        # ä¿å­˜åˆ°æ­·å²
        self.analysis_history.append(result)

        logger.info(f"æ€§èƒ½åˆ†æå®Œæˆï¼Œç¸½é«”åˆ†æ•¸: {overall_score:.1f}")
        return result

    def _identify_bottlenecks(
        self, metrics: PerformanceMetrics, profiler_result: ProfileResult = None
    ) -> List[Bottleneck]:
        """è­˜åˆ¥æ€§èƒ½ç“¶é ¸"""
        bottlenecks = []

        # å…§å­˜ç“¶é ¸æª¢æ¸¬
        memory_usage = metrics.get_average("memory_usage_mb")
        memory_percent = metrics.get_average("memory_percent")

        if memory_percent and memory_percent > 85:
            severity = min(1.0, (memory_percent - 85) / 15)  # 85-100% æ˜ å°„åˆ° 0-1
            bottlenecks.append(
                Bottleneck(
                    type=BottleneckType.MEMORY_BOUND,
                    severity=severity,
                    description=f"å…§å­˜ä½¿ç”¨ç‡é”åˆ° {memory_percent:.1f}%",
                    location="ç³»çµ±å…§å­˜",
                    impact=severity * 30,  # æœ€å¤šå½±éŸ¿30%æ€§èƒ½
                    evidence=[
                        f"å…§å­˜ä½¿ç”¨ç‡: {memory_percent:.1f}%",
                        f"å…§å­˜ä½¿ç”¨é‡: {memory_usage:.1f}MB" if memory_usage else "",
                    ],
                    recommendations=[
                        "å„ªåŒ–å…§å­˜ä½¿ç”¨",
                        "æª¢æŸ¥å…§å­˜æ´©æ¼",
                        "å¯¦æ–½å…§å­˜ç·©å­˜ç­–ç•¥",
                        "å¢åŠ ç³»çµ±å…§å­˜",
                    ],
                )
            )

        # CPUç“¶é ¸æª¢æ¸¬
        cpu_usage = metrics.get_average("cpu_usage")
        if cpu_usage and cpu_usage > 80:
            severity = min(1.0, (cpu_usage - 80) / 20)  # 80-100% æ˜ å°„åˆ° 0-1
            bottlenecks.append(
                Bottleneck(
                    type=BottleneckType.CPU_BOUND,
                    severity=severity,
                    description=f"CPUä½¿ç”¨ç‡é”åˆ° {cpu_usage:.1f}%",
                    location="ç³»çµ±CPU",
                    impact=severity * 40,  # æœ€å¤šå½±éŸ¿40%æ€§èƒ½
                    evidence=[f"CPUä½¿ç”¨ç‡: {cpu_usage:.1f}%"],
                    recommendations=[
                        "å„ªåŒ–è¨ˆç®—å¯†é›†å‹æ“ä½œ",
                        "ä½¿ç”¨ä¸¦è¡Œè™•ç†",
                        "å„ªåŒ–ç®—æ³•è¤‡é›œåº¦",
                        "è€ƒæ…®CPUå‡ç´š",
                    ],
                )
            )

        # IOç“¶é ¸æª¢æ¸¬ï¼ˆåŸºæ–¼å»¶é²ï¼‰
        io_bottlenecks = self._detect_io_bottlenecks(metrics)
        bottlenecks.extend(io_bottlenecks)

        # ç®—æ³•ç“¶é ¸æª¢æ¸¬ï¼ˆåŸºæ–¼æ€§èƒ½åˆ†æçµæœï¼‰
        if profiler_result:
            algo_bottlenecks = self._detect_algorithm_bottlenecks(profiler_result)
            bottlenecks.extend(algo_bottlenecks)

        return bottlenecks

    def _detect_io_bottlenecks(self, metrics: PerformanceMetrics) -> List[Bottleneck]:
        """æª¢æ¸¬IOç“¶é ¸"""
        bottlenecks = []

        # æª¢æŸ¥é«˜å»¶é²æ“ä½œ
        high_latency_threshold = 2.0  # 2ç§’

        for metric_name in metrics.metrics:
            if "latency_" in metric_name:
                avg_latency = metrics.get_average(metric_name)
                p95_latency = metrics.get_percentile(metric_name, 95)

                if avg_latency and avg_latency > high_latency_threshold:
                    operation = metric_name.replace("latency_", "")
                    severity = min(1.0, avg_latency / 10.0)  # 10ç§’å°æ‡‰æœ€é«˜åš´é‡æ€§

                    bottlenecks.append(
                        Bottleneck(
                            type=BottleneckType.IO_BOUND,
                            severity=severity,
                            description=f"æ“ä½œ {operation} å»¶é²éé«˜",
                            location=f"æ“ä½œ: {operation}",
                            impact=severity * 25,
                            evidence=[
                                f"å¹³å‡å»¶é²: {avg_latency:.2f}s",
                                f"P95å»¶é²: {p95_latency:.2f}s" if p95_latency else "",
                            ],
                            recommendations=[
                                "å„ªåŒ–IOæ“ä½œ",
                                "ä½¿ç”¨ç•°æ­¥è™•ç†",
                                "å¯¦æ–½æ“ä½œç·©å­˜",
                                "æª¢æŸ¥ç¶²çµ¡é€£æ¥",
                            ],
                        )
                    )

        return bottlenecks

    def _detect_algorithm_bottlenecks(self, profiler_result: ProfileResult) -> List[Bottleneck]:
        """æª¢æ¸¬ç®—æ³•ç“¶é ¸"""
        bottlenecks = []

        if not profiler_result.top_functions:
            return bottlenecks

        # æª¢æŸ¥ä½”ç”¨æ™‚é–“æœ€å¤šçš„å‡½æ•¸
        for func in profiler_result.top_functions[:3]:  # å‰3å€‹å‡½æ•¸
            if func.percentage > 25:  # ä½”ç”¨è¶…é25%æ™‚é–“
                severity = func.percentage / 100

                bottlenecks.append(
                    Bottleneck(
                        type=BottleneckType.ALGORITHM,
                        severity=severity,
                        description=f"å‡½æ•¸ {func.name} ä½”ç”¨éå¤šCPUæ™‚é–“",
                        location=func.name,
                        impact=func.percentage,
                        evidence=[
                            f"ä½”ç”¨æ™‚é–“æ¯”ä¾‹: {func.percentage:.1f}%",
                            f"ç¸½èª¿ç”¨æ¬¡æ•¸: {func.calls}",
                            f"ç´¯ç©æ™‚é–“: {func.cumulative_time:.3f}s",
                        ],
                        recommendations=[
                            "å„ªåŒ–ç®—æ³•å¯¦ç¾",
                            "æ¸›å°‘å‡½æ•¸èª¿ç”¨æ¬¡æ•¸",
                            "ä½¿ç”¨æ›´é«˜æ•ˆçš„æ•¸æ“šçµæ§‹",
                            "è€ƒæ…®ç·©å­˜è¨ˆç®—çµæœ",
                        ],
                    )
                )

        return bottlenecks

    def _analyze_trends(self, metrics: PerformanceMetrics) -> List[PerformanceTrend]:
        """åˆ†ææ€§èƒ½è¶¨å‹¢"""
        trends = []

        # åˆ†æé—œéµæŒ‡æ¨™çš„è¶¨å‹¢
        key_metrics = ["memory_usage_mb", "cpu_usage", "thread_count"]

        for metric_name in key_metrics:
            if metric_name in metrics.metrics and len(metrics.metrics[metric_name]) >= 5:
                trend = self._calculate_trend(metric_name, metrics.metrics[metric_name])
                if trend:
                    trends.append(trend)

        # åˆ†æå»¶é²è¶¨å‹¢
        latency_metrics = [name for name in metrics.metrics.keys() if "latency_" in name]
        for metric_name in latency_metrics:
            if len(metrics.metrics[metric_name]) >= 5:
                trend = self._calculate_trend(metric_name, metrics.metrics[metric_name])
                if trend:
                    trends.append(trend)

        return trends

    def _calculate_trend(self, metric_name: str, data_points: List) -> Optional[PerformanceTrend]:
        """è¨ˆç®—å–®å€‹æŒ‡æ¨™çš„è¶¨å‹¢"""
        if len(data_points) < 5:
            return None

        # å–æœ€è¿‘çš„æ•¸æ“šé»
        recent_values = [point.value for point in data_points[-10:]]
        timestamps = [point.timestamp for point in data_points[-10:]]

        if len(recent_values) < 3:
            return None

        # è¨ˆç®—ç·šæ€§è¶¨å‹¢
        try:
            # ç°¡å–®çš„ç·šæ€§å›æ­¸
            n = len(recent_values)
            x_mean = statistics.mean(range(n))
            y_mean = statistics.mean(recent_values)

            numerator = sum((i - x_mean) * (recent_values[i] - y_mean) for i in range(n))
            denominator = sum((i - x_mean) ** 2 for i in range(n))

            if denominator == 0:
                slope = 0
            else:
                slope = numerator / denominator

            # è¨ˆç®—è®ŠåŒ–ç‡ï¼ˆæ¯å°æ™‚ï¼‰
            time_span = (timestamps[-1] - timestamps[0]) / 3600  # è½‰æ›ç‚ºå°æ™‚
            if time_span > 0:
                change_rate = (slope * len(recent_values)) / time_span
            else:
                change_rate = 0

            # ç¢ºå®šè¶¨å‹¢æ–¹å‘
            if abs(change_rate) < 0.01:  # è®ŠåŒ–å¾ˆå°
                direction = "stable"
            elif change_rate > 0:
                direction = (
                    "degrading"
                    if "latency" in metric_name or "usage" in metric_name
                    else "improving"
                )
            else:
                direction = (
                    "improving"
                    if "latency" in metric_name or "usage" in metric_name
                    else "degrading"
                )

            # è¨ˆç®—ç½®ä¿¡åº¦ï¼ˆåŸºæ–¼æ•¸æ“šé»æ•¸é‡å’Œè®ŠåŒ–ä¸€è‡´æ€§ï¼‰
            confidence = min(1.0, len(recent_values) / 10.0)

            return PerformanceTrend(
                metric_name=metric_name,
                trend_direction=direction,
                change_rate=change_rate,
                confidence=confidence,
                data_points=len(recent_values),
            )

        except Exception as e:
            logger.warning(f"è¨ˆç®—è¶¨å‹¢æ™‚å‡ºéŒ¯ {metric_name}: {e}")
            return None

    def _calculate_overall_score(
        self, metrics: PerformanceMetrics, bottlenecks: List[Bottleneck]
    ) -> float:
        """è¨ˆç®—ç¸½é«”æ€§èƒ½åˆ†æ•¸"""
        base_score = 100.0

        # æ ¹æ“šç“¶é ¸æ‰£åˆ†
        for bottleneck in bottlenecks:
            penalty = bottleneck.severity * bottleneck.impact
            base_score -= penalty

        # æ ¹æ“šç³»çµ±æŒ‡æ¨™èª¿æ•´
        memory_percent = metrics.get_average("memory_percent")
        if memory_percent:
            if memory_percent > 90:
                base_score -= 20
            elif memory_percent > 80:
                base_score -= 10

        cpu_usage = metrics.get_average("cpu_usage")
        if cpu_usage:
            if cpu_usage > 90:
                base_score -= 15
            elif cpu_usage > 80:
                base_score -= 8

        # ç¢ºä¿åˆ†æ•¸åœ¨0-100ç¯„åœå…§
        return max(0.0, min(100.0, base_score))

    def _generate_insights(
        self,
        metrics: PerformanceMetrics,
        bottlenecks: List[Bottleneck],
        trends: List[PerformanceTrend],
    ) -> List[str]:
        """ç”Ÿæˆæ€§èƒ½æ´å¯Ÿ"""
        insights = []

        # ç“¶é ¸æ´å¯Ÿ
        if bottlenecks:
            severe_bottlenecks = [b for b in bottlenecks if b.severity > 0.7]
            if severe_bottlenecks:
                insights.append(f"ç™¼ç¾ {len(severe_bottlenecks)} å€‹åš´é‡æ€§èƒ½ç“¶é ¸ï¼Œéœ€è¦ç«‹å³é—œæ³¨")

            bottleneck_types = set(b.type for b in bottlenecks)
            if len(bottleneck_types) > 2:
                insights.append("ç³»çµ±å­˜åœ¨å¤šç¨®é¡å‹çš„æ€§èƒ½å•é¡Œï¼Œå»ºè­°ç³»çµ±æ€§å„ªåŒ–")
        else:
            insights.append("æœªç™¼ç¾æ˜é¡¯çš„æ€§èƒ½ç“¶é ¸ï¼Œç³»çµ±é‹è¡Œè‰¯å¥½")

        # è¶¨å‹¢æ´å¯Ÿ
        degrading_trends = [
            t for t in trends if t.trend_direction == "degrading" and t.confidence > 0.6
        ]
        if degrading_trends:
            insights.append(f"æª¢æ¸¬åˆ° {len(degrading_trends)} å€‹æ€§èƒ½æŒ‡æ¨™å‘ˆæƒ¡åŒ–è¶¨å‹¢")

        improving_trends = [
            t for t in trends if t.trend_direction == "improving" and t.confidence > 0.6
        ]
        if improving_trends:
            insights.append(f"æª¢æ¸¬åˆ° {len(improving_trends)} å€‹æ€§èƒ½æŒ‡æ¨™å‘ˆæ”¹å–„è¶¨å‹¢")

        # è³‡æºä½¿ç”¨æ´å¯Ÿ
        memory_usage = metrics.get_average("memory_usage_mb")
        if memory_usage:
            if memory_usage > 1000:
                insights.append("å…§å­˜ä½¿ç”¨é‡è¼ƒé«˜ï¼Œå»ºè­°ç›£æ§å…§å­˜æ´©æ¼")
            elif memory_usage < 100:
                insights.append("å…§å­˜ä½¿ç”¨æ•ˆç‡è‰¯å¥½")

        return insights

    def _generate_recommendations(
        self, bottlenecks: List[Bottleneck], trends: List[PerformanceTrend]
    ) -> List[str]:
        """ç”Ÿæˆå„ªåŒ–å»ºè­°"""
        recommendations = []

        # åŸºæ–¼ç“¶é ¸çš„å»ºè­°
        if bottlenecks:
            # æŒ‰åš´é‡æ€§æ’åº
            bottlenecks.sort(key=lambda x: x.severity, reverse=True)

            # æ·»åŠ æœ€åš´é‡ç“¶é ¸çš„å»ºè­°
            most_severe = bottlenecks[0]
            recommendations.extend(most_severe.recommendations[:2])  # å–å‰2å€‹å»ºè­°

            # å¦‚æœæœ‰å¤šå€‹åš´é‡ç“¶é ¸ï¼Œçµ¦å‡ºç³»çµ±æ€§å»ºè­°
            severe_count = len([b for b in bottlenecks if b.severity > 0.6])
            if severe_count > 2:
                recommendations.append("è€ƒæ…®é€²è¡Œç³»çµ±æ¶æ§‹é‡æ§‹ä»¥è§£æ±ºå¤šå€‹æ€§èƒ½å•é¡Œ")

        # åŸºæ–¼è¶¨å‹¢çš„å»ºè­°
        degrading_trends = [t for t in trends if t.trend_direction == "degrading"]
        if degrading_trends:
            recommendations.append("å¯†åˆ‡ç›£æ§æ€§èƒ½æƒ¡åŒ–çš„æŒ‡æ¨™ï¼ŒåŠæ™‚ä»‹å…¥")

        # é€šç”¨å»ºè­°
        if not recommendations:
            recommendations.extend(
                ["ç¶­æŒç•¶å‰çš„æ€§èƒ½ç›£æ§", "å®šæœŸé€²è¡Œæ€§èƒ½åŸºæº–æ¸¬è©¦", "å»ºç«‹æ€§èƒ½è­¦å ±æ©Ÿåˆ¶"]
            )

        return recommendations

    def generate_analysis_report(self, result: AnalysisResult) -> str:
        """ç”Ÿæˆåˆ†æå ±å‘Š"""
        lines = []
        lines.append("# æ€§èƒ½åˆ†æå ±å‘Š")
        lines.append(
            f"\n**åˆ†ææ™‚é–“**: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(result.analysis_timestamp))}"
        )
        lines.append(f"**ç¸½é«”æ€§èƒ½åˆ†æ•¸**: {result.overall_score:.1f}/100")

        # æ€§èƒ½ç­‰ç´š
        if result.overall_score >= 90:
            grade = "å„ªç§€ ğŸŸ¢"
        elif result.overall_score >= 75:
            grade = "è‰¯å¥½ ğŸŸ¡"
        elif result.overall_score >= 60:
            grade = "ä¸€èˆ¬ ğŸŸ "
        else:
            grade = "éœ€è¦æ”¹é€² ğŸ”´"

        lines.append(f"**æ€§èƒ½ç­‰ç´š**: {grade}")

        # ç“¶é ¸åˆ†æ
        if result.bottlenecks:
            lines.append(f"\n## ğŸ” ç“¶é ¸åˆ†æ")
            lines.append(f"ç™¼ç¾ {len(result.bottlenecks)} å€‹æ€§èƒ½ç“¶é ¸ï¼š")

            for i, bottleneck in enumerate(result.bottlenecks, 1):
                severity_icon = (
                    "ğŸ”´"
                    if bottleneck.severity > 0.7
                    else "ğŸŸ¡"
                    if bottleneck.severity > 0.4
                    else "ğŸŸ¢"
                )
                lines.append(f"\n**{i}. {bottleneck.description}** {severity_icon}")
                lines.append(f"- **é¡å‹**: {bottleneck.type.value}")
                lines.append(f"- **åš´é‡ç¨‹åº¦**: {bottleneck.severity:.1f}")
                lines.append(f"- **æ€§èƒ½å½±éŸ¿**: {bottleneck.impact:.1f}%")
                lines.append(f"- **ä½ç½®**: {bottleneck.location}")

                if bottleneck.evidence:
                    lines.append("- **è­‰æ“š**:")
                    for evidence in bottleneck.evidence:
                        if evidence:  # éæ¿¾ç©ºå­—ç¬¦ä¸²
                            lines.append(f"  - {evidence}")
        else:
            lines.append(f"\n## âœ… ç“¶é ¸åˆ†æ")
            lines.append("æœªç™¼ç¾æ˜é¡¯çš„æ€§èƒ½ç“¶é ¸")

        # è¶¨å‹¢åˆ†æ
        if result.trends:
            lines.append(f"\n## ğŸ“ˆ è¶¨å‹¢åˆ†æ")

            improving = [t for t in result.trends if t.trend_direction == "improving"]
            degrading = [t for t in result.trends if t.trend_direction == "degrading"]
            stable = [t for t in result.trends if t.trend_direction == "stable"]

            if improving:
                lines.append(f"\n**æ”¹å–„è¶¨å‹¢** ğŸŸ¢:")
                for trend in improving:
                    lines.append(f"- {trend.metric_name}: {trend.change_rate:+.2f}%/å°æ™‚")

            if degrading:
                lines.append(f"\n**æƒ¡åŒ–è¶¨å‹¢** ğŸ”´:")
                for trend in degrading:
                    lines.append(f"- {trend.metric_name}: {trend.change_rate:+.2f}%/å°æ™‚")

            if stable:
                lines.append(f"\n**ç©©å®šè¶¨å‹¢** ğŸŸ¡:")
                for trend in stable:
                    lines.append(f"- {trend.metric_name}")

        # æ´å¯Ÿ
        if result.insights:
            lines.append(f"\n## ğŸ’¡ é—œéµæ´å¯Ÿ")
            for insight in result.insights:
                lines.append(f"- {insight}")

        # å»ºè­°
        if result.recommendations:
            lines.append(f"\n## ğŸ¯ å„ªåŒ–å»ºè­°")
            for i, recommendation in enumerate(result.recommendations, 1):
                lines.append(f"{i}. {recommendation}")

        return "\n".join(lines)


def create_analyzer() -> PerformanceAnalyzer:
    """
    å‰µå»ºæ€§èƒ½åˆ†æå™¨å¯¦ä¾‹

    Returns:
        PerformanceAnalyzer: æ€§èƒ½åˆ†æå™¨å¯¦ä¾‹
    """
    return PerformanceAnalyzer()
