# Copyright (c) 2025 Bytedance Ltd. and/or its affiliates
# SPDX-License-Identifier: MIT

"""
AutoGen äº’å‹•å¼å·¥ä½œæµç¯„ä¾‹

å±•ç¤ºå¦‚ä½•ä½¿ç”¨äº’å‹•å¼åŠŸèƒ½é€²è¡Œç ”ç©¶å·¥ä½œæµã€‚
"""

import asyncio
import json
from typing import Dict, Any


# Mock AutoGen classes for compatibility
class MockOpenAIChatCompletionClient:
    """Mock OpenAIChatCompletionClient for compatibility"""

    def __init__(self, *args, **kwargs):
        self.config = kwargs.get("config", {})
        self.api_key = kwargs.get("api_key", "mock_key")
        self.base_url = kwargs.get("base_url", "https://api.openai.com/v1")

    def get(self, key, default=None):
        """Mock get method for config access"""
        if hasattr(self, key):
            return getattr(self, key)
        return self.config.get(key, default)

    def __getattr__(self, name):
        """Handle any other attribute access"""
        return lambda *args, **kwargs: None


OpenAIChatCompletionClient = MockOpenAIChatCompletionClient

from src.logging import get_logger
from ..interaction import (
    InteractiveWorkflowManager,
    run_interactive_research,
    run_non_interactive_research,
    display_welcome_message,
)
from ..controllers.conversation_manager import ConversationConfig

logger = get_logger(__name__)


async def example_interactive_research():
    """äº’å‹•å¼ç ”ç©¶å·¥ä½œæµç¯„ä¾‹"""
    print("\n=== äº’å‹•å¼ç ”ç©¶å·¥ä½œæµç¯„ä¾‹ ===\n")

    # å‰µå»ºæ¨¡å‹å®¢æˆ¶ç«¯
    model_client = OpenAIChatCompletionClient(
        model="gpt-4",
        api_key="your-api-key",  # è«‹æ›¿æ›ç‚ºå¯¦éš›çš„ API å¯†é‘°
    )

    # äº’å‹•å¼é…ç½®
    config = ConversationConfig(
        enable_background_investigation=True,
        max_plan_iterations=3,
        max_step_iterations=5,
        enable_human_feedback=True,  # å•Ÿç”¨äººå·¥åé¥‹
        auto_accept_plan=False,  # ä¸è‡ªå‹•æ¥å—è¨ˆåŠƒ
        debug_mode=True,
    )

    # ç”¨æˆ¶æŸ¥è©¢
    user_input = "ç ”ç©¶äººå·¥æ™ºæ…§åœ¨æ•™è‚²é ˜åŸŸçš„æ‡‰ç”¨å‰æ™¯å’ŒæŒ‘æˆ°"

    try:
        print("ğŸš€ å•Ÿå‹•äº’å‹•å¼ç ”ç©¶å·¥ä½œæµ...")
        print(f"ç ”ç©¶ä¸»é¡Œ: {user_input}\n")

        # åŸ·è¡Œäº’å‹•å¼ç ”ç©¶
        result = await run_interactive_research(
            user_input, model_client, enable_interaction=True, config=config
        )

        # é¡¯ç¤ºåŸ·è¡Œçµæœ
        print("\n" + "ğŸ“Š" * 30)
        print("åŸ·è¡Œçµæœæ‘˜è¦")
        print("ğŸ“Š" * 30)

        print(f"âœ… åŸ·è¡Œç‹€æ…‹: {'æˆåŠŸ' if result.get('success') else 'å¤±æ•—'}")
        print(f"ğŸ” ç ”ç©¶ä¸»é¡Œ: {result.get('research_topic', 'æœªçŸ¥')}")
        print(f"â±ï¸  åŸ·è¡Œæ™‚é–“: {result.get('execution_time', 0):.2f} ç§’")
        print(f"ğŸ”— æœƒè©±ID: {result.get('session_id', 'æœªçŸ¥')}")
        print(f"ğŸ¤ äº’å‹•æ¨¡å¼: {'å•Ÿç”¨' if result.get('interaction_enabled') else 'åœç”¨'}")

        if result.get("success"):
            execution_result = result.get("execution_result", {})
            print(f"\nğŸ“ˆ åŸ·è¡Œè©³æƒ…:")
            print(f"  - è¨ˆåŠƒç‹€æ…‹: {execution_result.get('plan_status', 'æœªçŸ¥')}")
            print(f"  - ç¸½æ­¥é©Ÿæ•¸: {execution_result.get('total_steps', 0)}")
            print(
                f"  - å®Œæˆæ­¥é©Ÿ: {execution_result.get('steps_by_status', {}).get('completed', 0)}"
            )
            print(f"  - å¤±æ•—æ­¥é©Ÿ: {execution_result.get('steps_by_status', {}).get('failed', 0)}")

            # é¡¯ç¤ºéƒ¨åˆ†å ±å‘Š
            final_report = result.get("final_report", "")
            if final_report:
                print(f"\nğŸ“„ å ±å‘Šé è¦½:")
                report_preview = (
                    final_report[:300] + "..." if len(final_report) > 300 else final_report
                )
                print(report_preview)
        else:
            print(f"\nâŒ éŒ¯èª¤: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")

    except Exception as e:
        logger.error(f"äº’å‹•å¼ç ”ç©¶ç¯„ä¾‹åŸ·è¡Œå¤±æ•—: {e}")
        print(f"åŸ·è¡Œå¤±æ•—: {e}")


async def example_non_interactive_research():
    """éäº’å‹•å¼ç ”ç©¶å·¥ä½œæµç¯„ä¾‹"""
    print("\n=== éäº’å‹•å¼ç ”ç©¶å·¥ä½œæµç¯„ä¾‹ ===\n")

    # å‰µå»ºæ¨¡å‹å®¢æˆ¶ç«¯
    model_client = OpenAIChatCompletionClient(
        model="gpt-4",
        api_key="your-api-key",  # è«‹æ›¿æ›ç‚ºå¯¦éš›çš„ API å¯†é‘°
    )

    # éäº’å‹•å¼é…ç½®
    config = ConversationConfig(
        enable_background_investigation=True,
        max_plan_iterations=2,
        max_step_iterations=3,
        enable_human_feedback=False,  # åœç”¨äººå·¥åé¥‹
        auto_accept_plan=True,  # è‡ªå‹•æ¥å—è¨ˆåŠƒ
        debug_mode=False,
    )

    # ç”¨æˆ¶æŸ¥è©¢
    user_input = "åˆ†æå€å¡ŠéˆæŠ€è¡“åœ¨ä¾›æ‡‰éˆç®¡ç†ä¸­çš„å„ªå‹¢å’Œå±€é™æ€§"

    try:
        print("ğŸ¤– å•Ÿå‹•è‡ªå‹•åŒ–ç ”ç©¶å·¥ä½œæµ...")
        print(f"ç ”ç©¶ä¸»é¡Œ: {user_input}\n")

        # åŸ·è¡Œéäº’å‹•å¼ç ”ç©¶
        result = await run_non_interactive_research(user_input, model_client, config)

        # é¡¯ç¤ºç°¡åŒ–çš„çµæœ
        print(f"åŸ·è¡Œç‹€æ…‹: {'âœ… æˆåŠŸ' if result.get('success') else 'âŒ å¤±æ•—'}")
        print(f"åŸ·è¡Œæ™‚é–“: {result.get('execution_time', 0):.2f} ç§’")

        if result.get("success"):
            print("\nè‡ªå‹•åŒ–å·¥ä½œæµåŸ·è¡Œå®Œæˆï¼")
        else:
            print(f"åŸ·è¡Œå¤±æ•—: {result.get('error')}")

    except Exception as e:
        logger.error(f"éäº’å‹•å¼ç ”ç©¶ç¯„ä¾‹åŸ·è¡Œå¤±æ•—: {e}")
        print(f"åŸ·è¡Œå¤±æ•—: {e}")


async def example_custom_interactive_workflow():
    """è‡ªå®šç¾©äº’å‹•å¼å·¥ä½œæµç¯„ä¾‹"""
    print("\n=== è‡ªå®šç¾©äº’å‹•å¼å·¥ä½œæµç¯„ä¾‹ ===\n")

    # å‰µå»ºæ¨¡å‹å®¢æˆ¶ç«¯
    model_client = OpenAIChatCompletionClient(
        model="gpt-4",
        api_key="your-api-key",  # è«‹æ›¿æ›ç‚ºå¯¦éš›çš„ API å¯†é‘°
    )

    # è‡ªå®šç¾©é…ç½®
    config = ConversationConfig(
        enable_background_investigation=True,
        max_plan_iterations=3,
        max_step_iterations=7,
        enable_human_feedback=True,
        auto_accept_plan=False,
        timeout_seconds=600,
        debug_mode=True,
    )

    # å‰µå»ºäº’å‹•å¼å·¥ä½œæµç®¡ç†å™¨
    interactive_manager = InteractiveWorkflowManager(model_client, config, enable_interaction=True)

    try:
        # ç”¨æˆ¶æŸ¥è©¢
        user_input = "è©•ä¼°è™›æ“¬å¯¦å¢ƒæŠ€è¡“åœ¨é†«ç™‚è¨“ç·´ä¸­çš„æ‡‰ç”¨æ•ˆæœ"

        print("ğŸ® å•Ÿå‹•è‡ªå®šç¾©äº’å‹•å¼å·¥ä½œæµ...")
        print(f"æŸ¥è©¢: {user_input}\n")

        # åŸ·è¡Œå·¥ä½œæµ
        result = await interactive_manager.run_interactive_research_workflow(user_input)

        # é¡¯ç¤ºè©³ç´°ç‹€æ…‹
        execution_status = interactive_manager.get_execution_status()
        print(f"\nğŸ“Š è©³ç´°åŸ·è¡Œç‹€æ…‹:")
        print(f"  - å·¥ä½œæµç‹€æ…‹: {execution_status.get('status')}")
        print(f"  - ç•¶å‰æ­¥é©Ÿ: {execution_status.get('current_step')}")
        print(f"  - ç¸½æ­¥é©Ÿæ•¸: {execution_status.get('total_steps')}")
        print(f"  - æš«åœç‹€æ…‹: {execution_status.get('paused')}")
        print(f"  - æœƒè©±ID: {execution_status.get('session_id')}")

        # åé¥‹çµ±è¨ˆ
        feedback_stats = execution_status.get("feedback_stats", {})
        if feedback_stats.get("total_requests", 0) > 0:
            print(f"\nğŸ’¬ äº’å‹•çµ±è¨ˆ:")
            print(f"  - ç¸½åé¥‹è«‹æ±‚: {feedback_stats.get('total_requests', 0)}")
            print(f"  - æ‰¹å‡†ç‡: {feedback_stats.get('approval_rate', 0):.1f}%")
            print(f"  - å¹³å‡å›æ‡‰æ™‚é–“: {feedback_stats.get('average_response_time', 0):.1f}ç§’")

        # æœ€çµ‚çµæœ
        if result.get("success"):
            print(f"\nğŸ‰ å·¥ä½œæµåŸ·è¡ŒæˆåŠŸï¼")
            print(f"ç¸½åŸ·è¡Œæ™‚é–“: {result.get('execution_time', 0):.2f} ç§’")
        else:
            print(f"\nâŒ å·¥ä½œæµåŸ·è¡Œå¤±æ•—: {result.get('error')}")

    except Exception as e:
        logger.error(f"è‡ªå®šç¾©äº’å‹•å¼å·¥ä½œæµåŸ·è¡Œå¤±æ•—: {e}")
        print(f"åŸ·è¡Œå¤±æ•—: {e}")

    finally:
        await interactive_manager.cleanup()


async def example_workflow_control():
    """å·¥ä½œæµæ§åˆ¶ç¯„ä¾‹"""
    print("\n=== å·¥ä½œæµæ§åˆ¶ç¯„ä¾‹ ===\n")

    # å‰µå»ºæ¨¡å‹å®¢æˆ¶ç«¯
    model_client = OpenAIChatCompletionClient(
        model="gpt-4",
        api_key="your-api-key",  # è«‹æ›¿æ›ç‚ºå¯¦éš›çš„ API å¯†é‘°
    )

    # é…ç½®
    config = ConversationConfig(
        enable_background_investigation=True,
        max_plan_iterations=2,
        max_step_iterations=5,
        enable_human_feedback=True,
        auto_accept_plan=False,
    )

    # å‰µå»ºäº’å‹•å¼ç®¡ç†å™¨
    interactive_manager = InteractiveWorkflowManager(model_client, config, enable_interaction=True)

    try:
        print("ğŸ›ï¸  å·¥ä½œæµæ§åˆ¶ç¤ºç¯„...")

        # æ¨¡æ“¬å·¥ä½œæµæ§åˆ¶æ“ä½œ
        print("\nğŸ“‹ å¯ç”¨æ§åˆ¶æ“ä½œ:")
        print("1. â¸ï¸  æš«åœå·¥ä½œæµ")
        print("2. â–¶ï¸  æ¢å¾©å·¥ä½œæµ")
        print("3. â¹ï¸  åœæ­¢å·¥ä½œæµ")
        print("4. ğŸ“Š æŸ¥çœ‹ç‹€æ…‹")

        # å±•ç¤ºç‹€æ…‹æŸ¥è©¢
        status = interactive_manager.get_execution_status()
        print(f"\nç•¶å‰ç‹€æ…‹: {status.get('status')}")

        # æ¨¡æ“¬æš«åœæ“ä½œ
        print("\nâ¸ï¸  åŸ·è¡Œæš«åœæ“ä½œ...")
        paused = await interactive_manager.pause_workflow()
        print(f"æš«åœçµæœ: {'æˆåŠŸ' if paused else 'å¤±æ•—'}")

        # æ¨¡æ“¬æ¢å¾©æ“ä½œ
        print("\nâ–¶ï¸  åŸ·è¡Œæ¢å¾©æ“ä½œ...")
        resumed = await interactive_manager.resume_workflow()
        print(f"æ¢å¾©çµæœ: {'æˆåŠŸ' if resumed else 'å¤±æ•—'}")

        # æ¨¡æ“¬åœæ­¢æ“ä½œ
        print("\nâ¹ï¸  åŸ·è¡Œåœæ­¢æ“ä½œ...")
        stopped = await interactive_manager.stop_workflow()
        print(f"åœæ­¢çµæœ: {'æˆåŠŸ' if stopped else 'å¤±æ•—'}")

        print("\nâœ… å·¥ä½œæµæ§åˆ¶ç¤ºç¯„å®Œæˆ")

    except Exception as e:
        logger.error(f"å·¥ä½œæµæ§åˆ¶ç¯„ä¾‹å¤±æ•—: {e}")
        print(f"æ§åˆ¶ç¤ºç¯„å¤±æ•—: {e}")

    finally:
        await interactive_manager.cleanup()


async def main():
    """ä¸»å‡½æ•¸ - åŸ·è¡Œæ‰€æœ‰äº’å‹•å¼ç¯„ä¾‹"""
    # é¡¯ç¤ºæ­¡è¿è¨Šæ¯
    await display_welcome_message()

    print("\nAutoGen äº’å‹•å¼å·¥ä½œæµç¯„ä¾‹")
    print("=" * 60)

    try:
        # åŸ·è¡Œå„ç¨®ç¯„ä¾‹
        await example_interactive_research()
        await example_non_interactive_research()
        await example_custom_interactive_workflow()
        await example_workflow_control()

        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰äº’å‹•å¼ç¯„ä¾‹åŸ·è¡Œå®Œæˆï¼")
        print("=" * 60)
        print("\nğŸ’¡ äº’å‹•å¼åŠŸèƒ½ç‰¹è‰²:")
        print("âœ… è¨ˆåŠƒå¯©æŸ¥å’Œä¿®æ”¹")
        print("â¸ï¸  å·¥ä½œæµæš«åœå’Œæ¢å¾©")
        print("ğŸ› ï¸  æ™ºèƒ½éŒ¯èª¤è™•ç†")
        print("ğŸ“Š å³æ™‚é€²åº¦ç›£æ§")
        print("ğŸ¤ äººæ©Ÿå”ä½œæ±ºç­–")

    except KeyboardInterrupt:
        print("\nç¯„ä¾‹åŸ·è¡Œè¢«ä¸­æ–·")
    except Exception as e:
        logger.error(f"ç¯„ä¾‹åŸ·è¡Œç•°å¸¸: {e}")
        print(f"ç¯„ä¾‹åŸ·è¡Œç•°å¸¸: {e}")


if __name__ == "__main__":
    # åŸ·è¡Œç¯„ä¾‹
    asyncio.run(main())
