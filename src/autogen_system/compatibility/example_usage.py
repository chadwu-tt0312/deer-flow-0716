# Copyright (c) 2025 Bytedance Ltd. and/or its affiliates
# SPDX-License-Identifier: MIT

"""
API ç›¸å®¹æ€§å±¤ä½¿ç”¨ç¯„ä¾‹

å±•ç¤ºå¦‚ä½•ä½¿ç”¨ AutoGen API ç›¸å®¹æ€§å±¤ã€‚
"""

import asyncio
from typing import Dict, Any


# Mock AutoGen classes for compatibility
class MockOpenAIChatCompletionClient:
    """Mock OpenAIChatCompletionClient for compatibility"""

    def __init__(self, *args, **kwargs):
        self.config = kwargs.get("config", {})
        self.api_key = kwargs.get("api_key", "mock_key")
        self.base_url = kwargs.get("base_url", "https://api.openai.com/v1")

    def get(self, key, default=None):
        """Mock get method for config access"""
        if hasattr(self, key):
            return getattr(self, key)
        return self.config.get(key, default)

    def __getattr__(self, name):
        """Handle any other attribute access"""
        return lambda *args, **kwargs: None


OpenAIChatCompletionClient = MockOpenAIChatCompletionClient

from src.logging import get_logger
from src.config.report_style import ReportStyle
from . import (
    AutoGenAPIAdapter,
    LangGraphCompatibilityLayer,
    ResponseMapper,
    StreamResponseMapper,
    run_compatibility_tests,
)

logger = get_logger(__name__)


async def example_api_adapter_usage():
    """API é©é…å™¨ä½¿ç”¨ç¯„ä¾‹"""
    print("=== API é©é…å™¨ä½¿ç”¨ç¯„ä¾‹ ===")

    # å‰µå»ºæ¨¡å‹å®¢æˆ¶ç«¯
    model_client = OpenAIChatCompletionClient(
        model="gpt-4",
        api_key="your-api-key",  # è«‹æ›¿æ›ç‚ºå¯¦éš›çš„ API å¯†é‘°
    )

    # å‰µå»º API é©é…å™¨
    adapter = AutoGenAPIAdapter(model_client)

    # æ¨¡æ“¬èŠå¤©è«‹æ±‚
    messages = [{"role": "user", "content": "è«‹åˆ†æäººå·¥æ™ºæ…§åœ¨é†«ç™‚é ˜åŸŸçš„æ‡‰ç”¨"}]

    print("é–‹å§‹è™•ç†èŠå¤©è«‹æ±‚...")

    try:
        # è™•ç†è«‹æ±‚ä¸¦æ”¶é›†äº‹ä»¶
        events = []
        async for event in adapter.process_chat_request(
            messages=messages,
            thread_id="example_thread",
            max_plan_iterations=1,
            max_step_num=2,
            auto_accepted_plan=True,
            enable_background_investigation=False,
            report_style=ReportStyle.ACADEMIC,
        ):
            events.append(event)
            print(
                f"äº‹ä»¶: {event.get('event')} - {event.get('data', {}).get('content', '')[:50]}..."
            )

            # é™åˆ¶äº‹ä»¶æ•¸é‡
            if len(events) >= 5:
                break

        print(f"âœ… æˆåŠŸè™•ç† {len(events)} å€‹äº‹ä»¶")

    except Exception as e:
        print(f"âŒ è™•ç†å¤±æ•—: {e}")


async def example_langgraph_compatibility():
    """LangGraph ç›¸å®¹æ€§ç¯„ä¾‹"""
    print("\n=== LangGraph ç›¸å®¹æ€§ç¯„ä¾‹ ===")

    # å‰µå»ºæ¨¡å‹å®¢æˆ¶ç«¯
    model_client = OpenAIChatCompletionClient(
        model="gpt-4",
        api_key="your-api-key",  # è«‹æ›¿æ›ç‚ºå¯¦éš›çš„ API å¯†é‘°
    )

    # å‰µå»ºç›¸å®¹æ€§å±¤
    compatibility_layer = LangGraphCompatibilityLayer(model_client)

    # æ¨¡æ“¬ LangGraph è¼¸å…¥æ ¼å¼
    input_data = {"messages": [{"role": "user", "content": "æ¸¬è©¦ LangGraph ç›¸å®¹æ€§"}]}

    config = {"thread_id": "langgraph_test", "max_plan_iterations": 1, "auto_accepted_plan": True}

    try:
        print("æ¸¬è©¦ ainvoke æ–¹æ³•...")
        result = await compatibility_layer.ainvoke(input_data, config)

        print(f"âœ… ainvoke æˆåŠŸ")
        print(f"   - è¨Šæ¯æ•¸é‡: {len(result.get('messages', []))}")
        print(f"   - æœ‰æœ€çµ‚å ±å‘Š: {'final_report' in result}")
        print(f"   - åŸ·è¡Œç‹€æ…‹: {result.get('execution_metadata', {}).get('success', 'unknown')}")

        print("\næ¸¬è©¦ astream æ–¹æ³•...")
        events = []
        async for event in compatibility_layer.astream(input_data, config):
            events.append(event)
            print(f"   äº‹ä»¶: {type(event).__name__}")

            # é™åˆ¶äº‹ä»¶æ•¸é‡
            if len(events) >= 3:
                break

        print(f"âœ… astream æˆåŠŸï¼Œæ”¶åˆ° {len(events)} å€‹äº‹ä»¶")

    except Exception as e:
        print(f"âŒ LangGraph ç›¸å®¹æ€§æ¸¬è©¦å¤±æ•—: {e}")


async def example_response_mapping():
    """éŸ¿æ‡‰æ˜ å°„ç¯„ä¾‹"""
    print("\n=== éŸ¿æ‡‰æ˜ å°„ç¯„ä¾‹ ===")

    # æ¨¡æ“¬ AutoGen åŸ·è¡Œçµæœ
    autogen_result = {
        "success": True,
        "research_topic": "AI åœ¨é†«ç™‚é ˜åŸŸçš„æ‡‰ç”¨",
        "final_report": "äººå·¥æ™ºæ…§åœ¨é†«ç™‚é ˜åŸŸå±•ç¾å‡ºå·¨å¤§æ½›åŠ›...",
        "execution_time": 15.7,
        "workflow_plan": {
            "id": "plan_123",
            "name": "é†«ç™‚ AI ç ”ç©¶è¨ˆåŠƒ",
            "description": "æ·±å…¥åˆ†æ AI é†«ç™‚æ‡‰ç”¨",
            "steps": [
                {
                    "step_id": "research_step",
                    "step_type": "research",
                    "description": "æ”¶é›† AI é†«ç™‚ç›¸é—œè³‡æ–™",
                    "timeout_seconds": 120,
                },
                {
                    "step_id": "analysis_step",
                    "step_type": "analysis",
                    "description": "åˆ†ææ”¶é›†åˆ°çš„è³‡æ–™",
                    "timeout_seconds": 180,
                },
            ],
        },
        "session_id": "session_456",
        "timestamp": "2025-01-08T16:00:00Z",
    }

    try:
        # æ˜ å°„åŸ·è¡Œçµæœ
        mapped_result = ResponseMapper.map_execution_result(autogen_result)

        print("âœ… åŸ·è¡Œçµæœæ˜ å°„æˆåŠŸ")
        print(f"   - æˆåŠŸç‹€æ…‹: {mapped_result.get('success')}")
        print(f"   - ç ”ç©¶ä¸»é¡Œ: {mapped_result.get('research_topic')}")
        print(f"   - åŸ·è¡Œæ™‚é–“: {mapped_result.get('execution_time')} ç§’")
        print(f"   - æœ‰å…ƒæ•¸æ“š: {'execution_metadata' in mapped_result}")

        # æ˜ å°„è¨ˆåŠƒæ•¸æ“š
        mapped_plan = ResponseMapper.map_plan_data(autogen_result["workflow_plan"])

        print(f"\nâœ… è¨ˆåŠƒæ˜ å°„æˆåŠŸ")
        print(f"   - è¨ˆåŠƒåç¨±: {mapped_plan.get('name')}")
        print(f"   - æ­¥é©Ÿæ•¸é‡: {len(mapped_plan.get('steps', []))}")
        print(f"   - é ä¼°æ™‚é–“: {mapped_plan.get('estimated_time')} åˆ†é˜")

        # æ¸¬è©¦æµå¼éŸ¿æ‡‰æ˜ å°„
        print(f"\næ¸¬è©¦æµå¼éŸ¿æ‡‰æ˜ å°„...")

        async def mock_stream():
            """æ¨¡æ“¬ AutoGen æµå¼äº‹ä»¶"""
            events = [
                {
                    "event": "message_chunk",
                    "data": {
                        "thread_id": "test",
                        "agent": "researcher",
                        "content": "é–‹å§‹ç ”ç©¶...",
                        "id": "msg_1",
                    },
                },
                {
                    "event": "message_chunk",
                    "data": {
                        "thread_id": "test",
                        "agent": "reporter",
                        "content": "ç ”ç©¶å®Œæˆ",
                        "finish_reason": "stop",
                        "id": "msg_2",
                    },
                },
            ]

            for event in events:
                yield event

        sse_events = []
        async for sse_event in StreamResponseMapper.map_stream_events(mock_stream()):
            sse_events.append(sse_event)

        print(f"âœ… æµå¼æ˜ å°„æˆåŠŸï¼Œç”Ÿæˆ {len(sse_events)} å€‹ SSE äº‹ä»¶")

    except Exception as e:
        print(f"âŒ éŸ¿æ‡‰æ˜ å°„æ¸¬è©¦å¤±æ•—: {e}")


async def example_compatibility_testing():
    """ç›¸å®¹æ€§æ¸¬è©¦ç¯„ä¾‹"""
    print("\n=== ç›¸å®¹æ€§æ¸¬è©¦ç¯„ä¾‹ ===")

    try:
        print("é‹è¡Œå®Œæ•´ç›¸å®¹æ€§æ¸¬è©¦...")
        results = await run_compatibility_tests()

        print(f"\næ¸¬è©¦çµæœ:")
        print(f"   - ç¸½æ¸¬è©¦: {results['total_tests']}")
        print(f"   - é€šé: {results['passed']}")
        print(f"   - å¤±æ•—: {results['failed']}")
        print(f"   - æˆåŠŸç‡: {results['success_rate']:.1f}%")

        if results["success_rate"] >= 80:
            print("âœ… ç›¸å®¹æ€§æ¸¬è©¦å¤§éƒ¨åˆ†é€šé")
        else:
            print("âŒ ç›¸å®¹æ€§æ¸¬è©¦å­˜åœ¨å•é¡Œ")

        # é¡¯ç¤ºè©³ç´°çµæœ
        print(f"\nè©³ç´°æ¸¬è©¦çµæœ:")
        for test_name, result in results["results"].items():
            status = "âœ…" if result.get("passed", False) else "âŒ"
            print(f"   {status} {test_name}")
            if not result.get("passed", False) and "error" in result:
                print(f"      éŒ¯èª¤: {result['error']}")

    except Exception as e:
        print(f"âŒ ç›¸å®¹æ€§æ¸¬è©¦å¤±æ•—: {e}")


async def main():
    """ä¸»å‡½æ•¸ - é‹è¡Œæ‰€æœ‰ç¯„ä¾‹"""
    print("AutoGen API ç›¸å®¹æ€§å±¤ä½¿ç”¨ç¯„ä¾‹")
    print("=" * 50)

    try:
        await example_api_adapter_usage()
        await example_langgraph_compatibility()
        await example_response_mapping()
        await example_compatibility_testing()

        print("\n" + "=" * 50)
        print("âœ… æ‰€æœ‰ç¯„ä¾‹åŸ·è¡Œå®Œæˆ")
        print("\nğŸ“š ä½¿ç”¨æŒ‡å—:")
        print("1. API é©é…å™¨: è™•ç†æ¨™æº–çš„èŠå¤©è«‹æ±‚")
        print("2. LangGraph ç›¸å®¹æ€§: èˆ‡ç¾æœ‰ LangGraph ä»£ç¢¼ç„¡ç¸«æ•´åˆ")
        print("3. éŸ¿æ‡‰æ˜ å°„: ç¢ºä¿å‰ç«¯æ¥æ”¶æ­£ç¢ºæ ¼å¼çš„æ•¸æ“š")
        print("4. ç›¸å®¹æ€§æ¸¬è©¦: é©—è­‰ç³»çµ±é›†æˆç‹€æ…‹")

    except Exception as e:
        print(f"\nâŒ ç¯„ä¾‹åŸ·è¡Œå¤±æ•—: {e}")


if __name__ == "__main__":
    # é‹è¡Œç¯„ä¾‹
    asyncio.run(main())
