# AutoGen æ¡†æ¶é…ç½®æª”æ¡ˆç¯„ä¾‹
# è¤‡è£½æ­¤æª”æ¡ˆç‚º conf_autogen.yaml ä¸¦æ ¹æ“šéœ€è¦èª¿æ•´è¨­å®š
# ç”Ÿç”¢ç’°å¢ƒé…ç½®
# environment: production
# debug: false

# =====================================
# ğŸ“‹ é‡è¦é…ç½®èªªæ˜
# =====================================
# ğŸ¯ å‹•æ…‹æ¨¡æ¿ç³»çµ± (Template-Only Mode)ï¼š
#    - æ‰€æœ‰æ™ºèƒ½é«”çš„ system_message éƒ½å¾å‹•æ…‹æ¨¡æ¿è¼‰å…¥
#    - ä¸å†ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„éœæ…‹ system_message
#    - æ¨¡æ¿è¼‰å…¥å¤±æ•—å°‡ç›´æ¥æ‹‹å‡ºç•°å¸¸ï¼Œç³»çµ±åœæ­¢é‹è¡Œ
#    - ç¢ºä¿ä»¥ä¸‹æ¨¡æ¿æ–‡ä»¶å­˜åœ¨ä¸”å¯ç”¨ï¼š
#      * coordinator.md
#      * planner.md
#      * researcher.md
#      * coder.md
#      * reporter.md
#      * background_investigator.md
#      * human_feedbacker.md
#
# ğŸ¤– ç ”ç©¶åœ˜éšŠ (Research Team)ï¼š
#    - é€™æ˜¯è™›æ“¬æ™ºèƒ½é«”ï¼Œä¸éœ€è¦åœ¨æ­¤é…ç½®
#    - ç”± AgentSelector å…§éƒ¨é‚è¼¯è™•ç†å”èª¿
#
# âš™ï¸ selector_config åƒæ•¸ï¼š
#    - max_plan_iterations: æœ€å¤§è¨ˆåŠƒè¿­ä»£æ¬¡æ•¸
#    - max_step_num: è¨ˆåŠƒä¸­çš„æœ€å¤§æ­¥é©Ÿæ•¸
#    - auto_accepted_plan: æ˜¯å¦è‡ªå‹•æ¥å—è¨ˆåŠƒ
#    - enable_background_investigation: æ˜¯å¦å•Ÿç”¨èƒŒæ™¯èª¿æŸ¥
# =====================================

# AutoGen åŸºæœ¬è¨­å®š
autogen:
  # é è¨­ LLM é…ç½®
  default_llm_config:
    temperature: 0.0
    max_tokens: 100_000
    timeout: 30

  # æ™ºèƒ½é«”åŸºæœ¬è¨­å®š
  agent_defaults:
    human_input_mode: "NEVER"
    code_execution_config: false

  # ç¾¤çµ„å°è©±è¨­å®šå·²ç§»é™¤ï¼ŒAutoGen SelectorGroupChat ä¸ä½¿ç”¨é€™äº›è¨­å®š

# æ™ºèƒ½é«”è§’è‰²é…ç½®
agents:
  coordinator_v3:
    name: "CoordinatorAgentV3"
    role: "coordinator"
    llm_config_override:
      temperature: 0.3

  planner_v3:
    name: "PlannerAgentV3"
    role: "planner"
    llm_config_override:
      temperature: 0.4

  researcher_v3:
    name: "ResearcherAgentV3"
    role: "researcher"
    tools:
      - "web_search"
      - "crawl_website"
      # - "local_search"
    llm_config_override:
      temperature: 0.2

  coder_v3:
    name: "CoderAgentV3"
    role: "coder"
    tools:
      - "python_repl"
    code_execution_config:
      work_dir: "temp_code_v3"
      use_docker: false
      timeout: 60

  reporter_v3:
    name: "ReporterAgentV3"
    role: "reporter"

  background_investigator_v3:
    name: "BackgroundInvestigatorAgentV3"
    role: "background_investigator"
    tools:
      - "web_search"
      - "crawl_website"
    llm_config_override:
      temperature: 0.3

  human_feedbacker_v3:
    name: "HumanFeedbackerAgentV3"
    role: "human_feedbacker"

# AgentSelector é…ç½® - åªä¿ç•™å¯¦éš›ä½¿ç”¨çš„åƒæ•¸
selector_config:
  max_plan_iterations: 1
  max_step_num: 3
  max_search_results: 3
  auto_accepted_plan: true
  enable_background_investigation: false

# å·¥å…·é…ç½®
tools:
  web_search:
    provider: "tavily" # tavily, brave_search, duckduckgo, arxiv, grounding_bing
    # max_results å·²ç§»é™¤ï¼Œä½¿ç”¨ param ä¸­çš„ "Max search results" è¨­å®š

  code_execution:
    timeout: 60
    max_execution_time: 300
    allowed_modules:
      - "pandas"
      - "numpy"
      - "matplotlib"
      - "requests"

# æ¨¡å‹é…ç½®
BASIC_MODEL:
  model: $AZURE_DEPLOYMENT_NAME_4_1_MINI
  azure_deployment: $AZURE_DEPLOYMENT_NAME_4_1_MINI
  azure_endpoint: $AZURE_OPENAI_ENDPOINT
  api_version: $BASIC_MODEL__API_VERSION
  api_key: $BASIC_MODEL__API_KEY
  verify_ssl: false
  model_type: "azure"

REASONING_MODEL:
  model: $AZURE_DEPLOYMENT_NAME_4_1
  azure_deployment: $AZURE_DEPLOYMENT_NAME_4_1
  azure_endpoint: $AZURE_OPENAI_ENDPOINT
  api_version: $BASIC_MODEL__API_VERSION
  api_key: $REASONING_MODEL__API_KEY
  verify_ssl: false
  model_type: "azure"

# Use Azure Open AI with key (from AutoGen example)
# provider: autogen_ext.models.openai.AzureOpenAIChatCompletionClient
# config:
#   model: $AZURE_DEPLOYMENT_NAME_4_1_MINI
#   azure_endpoint: $AZURE_OPENAI_ENDPOINT
#   azure_deployment: $AZURE_DEPLOYMENT_NAME_4_1_MINI
#   api_version: $BASIC_MODEL__API_VERSION
#   api_key: $BASIC_MODEL__API_KEY

# è¨˜éŒ„è¨­å®š
LOGGING:
  # æä¾›è€…é¸é …ï¼šfile, sqlite://path/to/db.sqlite, postgresql://user:pass@host:port/dbname
  provider: "file"

  # æ—¥èªŒç´šåˆ¥è¨­å®š
  level: "INFO"

  # è¼¸å‡ºè¨­å®š
  console_output: true

  # æª”æ¡ˆè¨­å®š
  file_settings:
    log_dir: "logs"
    max_days: 10
    compress_old_files: true

  # å¤–éƒ¨å¥—ä»¶æ—¥èªŒè¨­å®š
  external_loggers:
    level: "ERROR"

  # æ—¥èªŒæ ¼å¼è¨­å®š
  format:
    main: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    thread: "%(asctime)s - %(levelname)s - %(message)s"
